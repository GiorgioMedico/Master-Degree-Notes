\documentclass[openany]{book}

% Basic packages
\usepackage{amsmath, amsthm, graphicx, amsfonts, float, bm}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{listings}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{xcolor}
\usepackage[most]{tcolorbox}

% Page geometry
\usepackage{geometry}
\geometry{
 a4paper,
 total={170mm,237mm},
 left=20mm,
 top=30mm,
}

% Hyperlinks and headers
\usepackage[hidelinks]{hyperref}
\usepackage{fancyhdr}
\usepackage{tikz}
\pagestyle{fancy}
\fancyhf{}
\renewcommand{\headrulewidth}{0pt}
\fancyfoot[C]{\thepage}
\setlength{\footskip}{50pt}

% Image path
\graphicspath{ {./images/} }

% Custom commands and operators
\newcommand\at[2]{\left.#1\right|_{#2}}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\col}{col}
\DeclareMathOperator{\des}{des}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\newcommand{\notimplies}{%
\mathrel{{\ooalign{\hidewidth$\not\phantom{=}$\hidewidth\cr$\implies$}}}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\deriv}[1]{\displaystyle\frac{d}{d #1}}
\newcommand{\traj}{(\bar{\mathbf{x}},\bar{\mathbf{u}})}

% Theorem environments
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}{Proposition}[section]

\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{notation}{Notation}
\newtheorem*{corollary}{Corollary}

% Custom boxes for definitions and notes
\newcommand{\definitionbox}[1]{
\begin{tcolorbox}[colback=blue!5,colframe=blue!40!black,title=Definition]
 #1
\end{tcolorbox}
}
\newcommand{\note}[1]{
\begin{tcolorbox}[colback=green!5,colframe=green!40!black,title=Note]
 #1
\end{tcolorbox}
}

\title{Autonomous and Mobile Robotics}
\author{Giorgio Medico}
\date{fall semester 2024}


\begin{document}
\maketitle
\tableofcontents

\part{Mobile Robot Control}

\chapter{Configuration Space and Constraints}

\section{Configuration Space}

The configuration space represents the complete description of a mobile robot's position and orientation. It has the following key characteristics:

\begin{itemize}
    \item Its dimensions equal the number of parameters needed to uniquely describe the configuration of a mobile robot
    \item It is heavily dependent on the structure of the considered robot
    \item It is equivalent to the Joint Space for manipulators
\end{itemize}

Two important examples of configuration spaces are:

\begin{itemize}
    \item Unicycle:
        \begin{equation}
            q = [x \; y \; \theta]^T \in \R^2 \times S
        \end{equation}
        
    \item Bicycle:
        \begin{equation}
            q = [x \; y \; \theta \; \gamma]^T \in \R^2 \times S^2
        \end{equation}
\end{itemize}

\section{Constraints}

\definitionbox{A constraint is any condition imposed on a material system that prevents it from assuming a generic position and/or act of motion.}

\definitionbox{A material system is subject to holonomic constraints if finite relations between the coordinates of the system are present (position constraints) or if differentiable/integrable relations between the coordinates of the system are present.}

\definitionbox{A constraint is said to be non-holonomic if the differential relation between the coordinates is not reducible to finite form.}

\section{Non-Holonomic Constraints}

A fundamental simplifying assumption in mobile robotics is that each wheel rolls without slipping. This introduces several important characteristics:

\begin{itemize}
    \item Each wheel introduces a non-holonomic constraint since it does not allow normal translations to the rolling direction
    \item The wheel constrains the instant robot mobility, without typically reducing the configuration space (e.g., parallel parking)
\end{itemize}

Without constraints, the general motion equations are:
\begin{equation}
    \begin{cases}
        \dot{x} = v_t \cos \theta + v_n \cos(\theta + \frac{\pi}{2}) \\
        \dot{y} = v_t \sin \theta + v_n \sin(\theta + \frac{\pi}{2})
    \end{cases}
\end{equation}

Since there is no slipping in the normal direction ($v_n = 0$), this reduces to:
\begin{equation}
    \begin{cases}
        \dot{x} = v_t \cos \theta \\
        \dot{y} = v_t \sin \theta
    \end{cases}
    \;\; \Leftrightarrow \;\;
    \tan \theta = \frac{\dot{y}}{\dot{x}}
    \;\; \Leftrightarrow \;\;
    \dot{x} \sin \theta - \dot{y} \cos \theta = 0
\end{equation}

The last equation represents the mobility constraint.

\section{Constraints in Pfaffian Form}

Constraints can be expressed in different forms:
\begin{itemize}
    \item Constraint vector equation for a single wheel: $a(q)\dot{q} = 0$
    \item Constraints matrix equation for N wheels: $A(q)\dot{q} = 0$
\end{itemize}

A constraint that can be written as $A(q)\dot{q} = 0$ is said to be in Pfaffian form. For non-holonomic constraints:
\begin{itemize}
    \item They cannot be fully integrated
    \item They cannot be written in the configuration space
    \item They do not restrict the space of configurations but rather the instant robot mobility
\end{itemize}

\subsection{Admissible Speeds}
The admissible speeds may be generated by a matrix $G(q)$ such that:
\begin{equation}
    \text{Im}(G(q)) = \text{Ker}(A(q)), \;\; \forall q \in C
\end{equation}
where $C$ represents the Configuration Space.

\chapter{Kinematic Models of Mobile Robots}

\section{General Kinematic Model}

\subsection{Basic Formulation}
The general kinematic model of a wheeled mobile robot (WMR) can be expressed as:
\begin{equation}
    \dot{q} = G(q)v
\end{equation}

This model:
\begin{itemize}
    \item Represents the allowable directions of motion in the configuration space (allowable velocities)
    \item Binds speeds in the operational space with speeds in the configuration space
    \item Is essential for solving common mobile robotics problems:
    \begin{itemize}
        \item Trajectory planning
        \item Control (High level)
        \item Robot localization
    \end{itemize}
\end{itemize}

\section{Unicycle Model}

\definitionbox{A unicycle is a vehicle with a single adjustable wheel. The configuration is described by $q = [x \; y \; \theta]^T$}

\subsection{Constraints and Pfaffian Form}
The unicycle is subject to the constraint:
\begin{equation}
    \dot{x} \sin \theta - \dot{y} \cos \theta = 0
\end{equation}

In Pfaffian form, $A(q)\dot{q} = 0$ with:
\begin{equation}
    \begin{cases}
        A(q) = [\sin \theta, -\cos \theta, 0] \\
        q = [x \; y \; \theta]^T
    \end{cases}
\end{equation}

The kernel of $A(q)$ provides the admissible velocities:
\begin{equation}
    \text{Ker}(A(q)) = \text{span}\left\{\begin{bmatrix}\cos \theta\\\sin \theta\\0\end{bmatrix}, \begin{bmatrix}0\\0\\1\end{bmatrix}\right\} = \text{Im}(G(q))
\end{equation}

\subsection{Kinematic Model}
The complete unicycle kinematic model is:
\begin{equation}
    \dot{q} = \begin{bmatrix}\cos \theta\\\sin \theta\\0\end{bmatrix}v + \begin{bmatrix}0\\0\\1\end{bmatrix}\omega = \begin{bmatrix}\cos \theta & 0\\\sin \theta & 0\\0 & 1\end{bmatrix}\begin{bmatrix}v\\\omega\end{bmatrix}
\end{equation}

where:
\begin{itemize}
    \item $v$: linear velocity of the contact point between wheel and ground (product of wheel angular velocity and radius)
    \item $\omega$: angular velocity of the robot around the vertical axis
\end{itemize}

The configuration can be modified by controlling inputs $v$ and $\omega$.

\subsection{Practical Implementations}
Due to stability issues with the original unicycle design, two main equivalent structures are commonly used:

\subsubsection{Synchronized Drive Model}
\begin{itemize}
    \item Uses adjustable parallel wheels
    \item Control inputs: $[v \; \omega]^T$
    \item Configuration: $[x \; y \; \theta]^T$ represents position of any chosen point and robot orientation
\end{itemize}

\subsubsection{Differential Drive Model}
\begin{itemize}
    \item Uses two wheels separately controlled
    \item Includes a passive wheel for static support
    \item Configuration: $[x \; y \; \theta]^T$ represents position of the wheelbase midpoint and robot orientation
\end{itemize}

\subsection{Differential Drive Kinematics}
Key parameters:
\begin{itemize}
    \item $\omega_R$: right wheel speed
    \item $\omega_L$: left wheel speed
    \item $d$: wheelbase
    \item $r$: wheel radius
\end{itemize}

The model with inputs $\omega_R, \omega_L$ is:
\begin{equation}
    \begin{bmatrix}v\\\omega\end{bmatrix} = \begin{bmatrix}\frac{r}{2} & \frac{r}{2}\\\frac{r}{d} & -\frac{r}{d}\end{bmatrix}\begin{bmatrix}\omega_R\\\omega_L\end{bmatrix}
\end{equation}

In state space:
\begin{equation}
    \dot{q} = \begin{bmatrix}\dot{x}\\\dot{y}\\\dot{\theta}\end{bmatrix} = \begin{bmatrix}\cos \theta & 0\\\sin \theta & 0\\0 & 1\end{bmatrix}\begin{bmatrix}\frac{r}{2} & \frac{r}{2}\\\frac{r}{d} & -\frac{r}{d}\end{bmatrix}\begin{bmatrix}\omega_R\\\omega_L\end{bmatrix}
\end{equation}

\section{Bicycle Kinematic Model}

\definitionbox{A bicycle is a vehicle having a caster (adjustable wheel) and a fixed wheel with their rotation axes perpendicular to the longitudinal plane. We consider only the case with front-wheel steering.}

The configuration is described by:
\begin{equation}
    q = \begin{bmatrix}x\\y\\\theta\\\gamma\end{bmatrix}
\end{equation}

\subsection{Constraints}
The system is subject to two constraints, one for each wheel:
\begin{equation}
    \begin{cases}
        \dot{x}_f \sin(\theta + \gamma) - \dot{y}_f \cos(\theta + \gamma) = 0\\
        \dot{x}_r \sin(\theta) - \dot{y}_r \cos(\theta) = 0
    \end{cases}
\end{equation}

where $(x_f, y_f)$ represents the front wheel contact point and $(x_r, y_r)$ the rear wheel contact point, related by:
\begin{equation}
    \begin{cases}
        x_f = x_r + L\cos\theta\\
        y_f = y_r + L\sin\theta
    \end{cases}
\end{equation}

The kinematic constraints in Pfaffian form are:
\begin{equation}
    A(q) = \begin{bmatrix}
        \sin\theta & -\cos\theta & 0 & 0\\
        \sin(\theta + \gamma) & -\cos(\theta + \gamma) & -L\cos\gamma & 0
    \end{bmatrix}
\end{equation}

\subsection{Complete Kinematic Model}
The bicycle kinematic model with control inputs $v$ (linear traction velocity) and $\omega$ (angular velocity of steering) is:
\begin{equation}
    \dot{q} = \begin{bmatrix}
        \cos\theta\cos\gamma \\
        \sin\theta\cos\gamma \\
        \frac{1}{L}\sin\gamma \\
        0
    \end{bmatrix}v + \begin{bmatrix}
        0 \\
        0 \\
        0 \\
        1
    \end{bmatrix}\omega
\end{equation}

\section{Swedish Wheel Kinematics}

The Swedish wheel allows decomposition of velocity into two components:
\begin{equation}
    v = v_w\hat{x}_w + v_r(\hat{x}_w\cos\alpha + \hat{y}_w\sin\alpha)
\end{equation}

where:
\begin{itemize}
    \item $v_w\hat{x}_w$ is the driven component
    \item $v_r(\hat{x}_w\cos\alpha + \hat{y}_w\sin\alpha)$ is the rolling component
\end{itemize}

This can be rewritten as:
\begin{equation}
    v = (v_w + v_r\cos\alpha)\hat{x}_w + v_r\hat{y}_w\sin\alpha = v_x\hat{x}_w + v_y\hat{y}_w
\end{equation}

The relationships between velocities are:
\begin{equation}
    \begin{cases}
        v_r = v_y/\sin\alpha\\
        v_w = v_x - v_y\cot\alpha\\
        \omega = v_w/R
    \end{cases}
\end{equation}

For a vehicle with multiple Swedish wheels, the velocity at each wheel contact point is:
\begin{equation}
    {}^B v_i = {}^B v_B + {}^B\omega\hat{z}_B \times {}^B p_i
\end{equation}

where:
\begin{itemize}
    \item ${}^B v_B = \sqrt{\dot{x}^2 + \dot{y}^2}$ is the desired body velocity
    \item ${}^B\omega = \dot{\theta}$ is the angular rate
    \item ${}^B p_i$ are the wheel contact points
\end{itemize}


\chapter{Robot Control Architecture}

\section{Elementary Motion Tasks}

There are three fundamental types of motion tasks for mobile robots:

\begin{enumerate}
    \item Point-to-Point Transfer
    \begin{itemize}
        \item Example: parallel parking
        \item Movement from initial pose to final pose
        \item No specific path requirements
    \end{itemize}

    \item Trajectory Following (no time constraints)
    \begin{itemize}
        \item Geometric specification using parameter $s$
        \item Robot must follow a specific spatial path
        \item Timing of the motion is not critical
    \end{itemize}

    \item Trajectory Tracking (with time constraints)
    \begin{itemize}
        \item Time-based specification using parameter $t$
        \item Robot must be at specific points at specific times
        \item Both spatial and temporal accuracy required
    \end{itemize}
\end{enumerate}

\section{Control System Architecture}

The control system of a mobile robot consists of several interconnected components:

\subsection{Main Components}

\begin{itemize}
    \item \textbf{Task Planning}
        \begin{itemize}
            \item Generates reference trajectory $q_{ref}$
            \item Considers mission objectives and constraints
        \end{itemize}
        
    \item \textbf{High-Level Control}
        \begin{itemize}
            \item Processes error signals
            \item Generates control commands
        \end{itemize}
        
    \item \textbf{Low-Level Control}
        \begin{itemize}
            \item Interfaces with actuators
            \item Implements basic motion commands
        \end{itemize}
        
    \item \textbf{Actuation System}
        \begin{itemize}
            \item DC motors, stepper motors
            \item Converts control signals to physical motion
        \end{itemize}
        
    \item \textbf{End-Effector}
        \begin{itemize}
            \item General purpose tools
            \item Grippers, hands
        \end{itemize}
\end{itemize}

\subsection{Sensor Systems}

The robot utilizes two types of sensors:

\subsubsection{Proprioceptive Sensors}
Internal state measurement devices:
\begin{itemize}
    \item Encoders
    \item Gyroscopes
\end{itemize}

\subsubsection{Exteroceptive Sensors}
Environmental measurement devices:
\begin{itemize}
    \item Bumpers
    \item Rangefinders (infrared, ultrasonic)
    \item Laser scanners
    \item Vision systems (mono, stereo)
\end{itemize}

\section{Control Hierarchy}

\subsection{Low-Level Control}
\begin{itemize}
    \item Implements high-gain PI controllers for motor control
    \item Ensures robot follows desired speed profile
    \item Handles only actuator control based on high-level instructions
    \item Makes robot behave as a purely kinematic system when gains are sufficiently high
\end{itemize}

\note{The low-level control system deals exclusively with the robot actuators and is not affected by the non-holonomic constraints introduced by the wheels.}

\subsection{High-Level Control}

Core functions:
\begin{itemize}
    \item Processes and computes signals for low-level controller
    \item Uses sensor data for feedback
    \item Treats robot as a purely kinematic system
    \item Generates speed control signals
\end{itemize}

\section{Control Challenges}
The control system must address several key challenges:

\subsection{Low-Level Control Challenges}
\begin{itemize}
    \item Internal loop control for robot actuation
    \item Implementation of PI control for electric drives (linear systems)
    \item Management of motor dynamics
\end{itemize}

\subsection{High-Level Control Challenges}
\begin{itemize}
    \item Definition of motion and behavior based on task requirements
    \item Integration of kinematic model constraints
    \item Handling of wheel constraints
    \item Control of nonlinear and complex system dynamics
\end{itemize}

\note{The overall control architecture must seamlessly integrate both levels while respecting the robot's physical constraints and achieving the desired motion objectives.}

\chapter{Motion Control Strategies}

\section{Motion Control Problem}

\definitionbox{Given a trajectory or a desired configuration, the motion control problem involves designing a control law that leads the robot to the desired configuration or to follow the trajectory (high-level control).}

Key characteristics:
\begin{itemize}
    \item Control uses the kinematic model
    \item Kinematic inputs act directly on configuration variables
    \item For unicycle and bicycle models, control inputs are $v$ and $\omega$
    \item Direct torque control on wheels is typically not possible due to low-level control loop
\end{itemize}

\section{Control Problem Categories}

\subsection{Configuration Regulation}
The robot must reach a desired configuration starting from an initial configuration:
\begin{itemize}
    \item Initial: $q_0 = [x_0 \; y_0 \; \theta_0]^T$
    \item Desired: $q_d = [x_d \; y_d \; \theta_d]^T$
\end{itemize}

\subsection{Trajectory Control}
The robot must asymptotically follow a desired Cartesian trajectory $[x_d(t), y_d(t)]^T$ from initial configuration $q_0 = [x_0 \; y_0 \; \theta_0]^T$. Two variants:

\begin{enumerate}
    \item \textbf{Trajectory Following}
        \begin{itemize}
            \item Depends on geometric parameter $s$
            \item No time constraints
        \end{itemize}
        
    \item \textbf{Trajectory Tracking}
        \begin{itemize}
            \item Depends on time parameter $t$
            \item Timing specifications must be met
        \end{itemize}
\end{enumerate}

\section{Point-to-Point Motion Control}

\subsection{Moving to a Point}
Objective: Move to goal point $(x^*, y^*)$

Control law:
\begin{itemize}
    \item Robot velocity proportional to distance from goal:
        \begin{equation}
            v^* = K_v\sqrt{(x^* - x)^2 + (y^* - y)^2}, \quad K_v > 0
        \end{equation}
    
    \item Steering angle points to goal:
        \begin{equation}
            \theta^* = \text{atan2}(y^* - y, x^* - x)
        \end{equation}
    
    \item Proportional steering control:
        \begin{equation}
            \gamma = K_h(\theta^* - \theta), \quad K_h > 0
        \end{equation}
\end{itemize}

\note{Since $\{\theta^*, \theta\} \in S$, these are not real numbers but angles on the unit circle.}

\subsection{Line Following}
Objective: Follow line $ax + by + c = 0$

Control strategy:
\begin{enumerate}
    \item Distance minimization:
        \begin{equation}
            \alpha_d = -K_d d, \quad K_d > 0, \quad d = \frac{ax + by + c}{\sqrt{a^2 + b^2}}
        \end{equation}
    
    \item Heading angle alignment:
        \begin{equation}
            \alpha_h = K_h(\theta^* - \theta), \quad K_h > 0, \quad \theta^* = \text{atan}\left(-\frac{a}{b}\right)
        \end{equation}
    
    \item Combined control law:
        \begin{equation}
            \gamma = \alpha_d + \alpha_h
        \end{equation}
\end{enumerate}

\section{Pose Control}

\subsection{Moving to a Specific Pose}
Objective: Drive robot to pose $(x^*, y^*, \theta^*)$

Transformation to polar coordinates:
\begin{equation}
    \begin{cases}
        \rho = \sqrt{(x^* - x)^2 + (y^* - y)^2} \\
        \alpha = \text{atan2}(y^* - y, x^* - x) - \theta \\
        \beta = -\theta - \alpha + \theta^*
    \end{cases}
\end{equation}

System dynamics:
\begin{equation}
    \begin{bmatrix}
        \dot{\rho} \\
        \dot{\alpha} \\
        \dot{\beta}
    \end{bmatrix} = 
    \begin{bmatrix}
        -\cos\alpha & 0 \\
        \frac{\sin\alpha}{\rho} & -1 \\
        -\frac{\sin\alpha}{\rho} & 0
    \end{bmatrix}
    \begin{bmatrix}
        v \\ \omega
    \end{bmatrix}
\end{equation}

Control law:
\begin{equation}
    \begin{cases}
        v = k_\rho\rho \\
        \omega = k_\alpha\alpha + k_\beta\beta
    \end{cases}
\end{equation}

Stability conditions:
\begin{itemize}
    \item $k_\rho > 0$
    \item $k_\beta < 0$
    \item $k_\alpha - k_\rho > 0$
\end{itemize}

\section{Input-Output State Feedback Linearization}

\subsection{Basic Concept}
Define point B outside wheels axle for vehicle control:
\begin{equation}
    \begin{cases}
        x_b = x_r + b\cos\theta_r \\
        y_b = y_r + b\sin\theta_r
    \end{cases}, \quad b \neq 0
\end{equation}

Benefits:
\begin{itemize}
    \item Point B has no constraints
    \item Can move instantly in any direction
    \item Allows lateral motion relative to vehicle direction
\end{itemize}

\subsection{Control System}
Decoupled inputs:
\begin{equation}
    \begin{cases}
        \dot{x}_b = v_{x,b} \\
        \dot{y}_b = v_{y,b}
    \end{cases}
\end{equation}

System dynamics:
\begin{equation}
    \begin{cases}
        \dot{x}_b = \dot{x}_r - b\omega\sin\theta_r = v\cos\theta_r - b\omega\sin\theta_r \\
        \dot{y}_b = \dot{y}_r + b\omega\cos\theta_r = v\sin\theta_r + b\omega\cos\theta_r
    \end{cases}
\end{equation}

Matrix form:
\begin{equation}
    \begin{bmatrix}
        \dot{x}_b \\ \dot{y}_b
    \end{bmatrix} =
    \begin{bmatrix}
        \cos\theta_r & -b\sin\theta_r \\
        \sin\theta_r & b\cos\theta_r
    \end{bmatrix}
    \begin{bmatrix}
        v \\ \omega
    \end{bmatrix}
\end{equation}

\subsection{Trajectory Tracking}
For trajectory $(x_d(\cdot), y_d(\cdot))$, tracking control law:
\begin{equation}
    \begin{cases}
        \dot{x}_b = v_{x,b} = \dot{x}_d + K_1(x_d - x_b) \\
        \dot{y}_b = v_{y,b} = \dot{y}_d + K_2(y_d - y_b)
    \end{cases}
\end{equation}

Error dynamics:
\begin{equation}
    \begin{cases}
        e_x = x_d - x_b \\
        e_y = y_d - y_b
    \end{cases}
    \Rightarrow
    \begin{cases}
        \dot{e}_x + K_1e_x = 0 \\
        \dot{e}_y + K_2e_y = 0
    \end{cases}
    \Rightarrow
    \begin{cases}
        e_x \to 0 \\
        e_y \to 0
    \end{cases}
\end{equation}

\section{Trajectory Following}

\subsection{Time-Based Following}
Objective: Follow sequence of points $(x^*(t), y^*(t))$

Control strategy:
\begin{itemize}
    \item Maintain distance $d^*$ behind pursuit point:
        \begin{equation}
            e = \sqrt{(x^* - x)^2 + (y^* - y)^2} - d^*
        \end{equation}
    
    \item PI velocity controller:
        \begin{equation}
            v^* = K_he + K_i\int e\,dt
        \end{equation}
    
    \item Steering control:
        \begin{equation}
            \gamma = K_h(\theta^* - \theta), \quad K_h > 0, \quad \theta^* = \text{atan2}(y^* - y, x^* - x)
        \end{equation}
\end{itemize}

\note{The integral term is necessary to provide nonzero velocity when tracking error is zero.}

\chapter{Motion Planning}

\section{Planning Problem}

\definitionbox{The motion planning problem involves determining a trajectory in the configuration space to take the robot from an initial configuration to a final configuration, where both configurations must be feasible.}

Key requirements:
\begin{itemize}
    \item Initial and final configurations (boundary conditions) must be compatible with kinematic constraints
    \item All points along the trajectory must respect kinematic constraints
\end{itemize}

\definitionbox{A trajectory is not feasible if it requires the robot to perform motion incompatible with its kinematic constraints. For example, a unicycle cannot perform lateral translation.}

\section{Space-Time Trajectory Separation}

\subsection{Problem Formulation}
Plan trajectory $q(t), t \in [t_i, t_f]$ that takes robot from:
\begin{itemize}
    \item Initial configuration: $q(t_i) = q_i$
    \item Final configuration: $q(t_f) = q_f$
\end{itemize}

The trajectory $q(t)$ can be decomposed into:
\begin{enumerate}
    \item Path $q(s)$ with $\frac{dq(s)}{ds} \neq 0, \forall s$
    \item Motion law $s = s(t)$, where $s_i \leq s \leq s_f$, with:
        \begin{equation}
            \begin{cases}
                s(t_i) = s_i \\
                s(t_f) = s_f \\
                \dot{s}(t) \geq 0 \text{ (monotonic)}
            \end{cases}
        \end{equation}
\end{enumerate}

\note{A typical choice for $s$ is the curvilinear abscissa along the path, with $s_i = 0$ and $s_f = L$.}

\subsection{Mathematical Analysis}
Space-time separation of trajectory:
\begin{equation}
    \dot{q} = \frac{dq}{dt} = \frac{dq}{ds}\dot{s} = q'\dot{s}
\end{equation}

where:
\begin{itemize}
    \item $q'$ is tangent to path in configuration space for growing $s$
    \item $\dot{s}$ modulates the speed along the path
\end{itemize}

From Pfaffian form of non-holonomic constraints:
\begin{equation}
    \begin{cases}
        A(q)\dot{q} = A(q)q'\dot{s} = 0 \\
        \dot{s} > 0, \forall t \in [t_i, t_f]
    \end{cases}
    \Rightarrow A(q)q' = 0
\end{equation}

A feasible path satisfies:
\begin{equation}
    q' = G(q)\tilde{u}
\end{equation}

\section{Control Input Generation}

\subsection{Planning Problem}
Given:
\begin{itemize}
    \item Geometric path with known inputs $\tilde{u}$
    \item Motion law $s(t)$ defining path speed
\end{itemize}

Problem: How to combine these to obtain robot control inputs?

\subsection{Mathematical Derivation}
\begin{equation}
    \begin{aligned}
        q &= G(q)u \\
        q' &= G(q)\tilde{u}(s) \\
        \frac{dq}{ds}\dot{s} &= G(q)\tilde{u}(s)\dot{s} \\
        \dot{q} &= G(q)\tilde{u}(s)\dot{s} \\
        \dot{q} &= G(q)u(t)
    \end{aligned}
\end{equation}

Therefore:
\begin{equation}
    \tilde{u}(s)\dot{s} = u(t)
\end{equation}

\section{Unicycle Path Planning}

\subsection{Feasibility Conditions}
For the unicycle, non-holonomic constraints imply:
\begin{equation}
    [sin \theta \; -\cos \theta \; 0]q' = x'\sin \theta - y'\cos \theta = 0
\end{equation}

This means Cartesian speed must align with motion direction (no lateral slip).

Feasible paths are given by:
\begin{equation}
    \begin{cases}
        x' = \tilde{v}\cos \theta \\
        y' = \tilde{v}\sin \theta \\
        \theta' = \tilde{\omega}
    \end{cases}
\end{equation}

Kinematic inputs derived from geometric ones:
\begin{equation}
    \begin{cases}
        v(t) = \tilde{v}\dot{s} \\
        \omega(t) = \tilde{\omega}\dot{s}
    \end{cases}
\end{equation}

\section{Differential Flatness Planning}

\definitionbox{A generic nonlinear dynamic system $\dot{x} = f(x) + g(x)u$ has the property of differential flatness if there exists a set of outputs $y$, called flat, such that the system's state $x$ and input $u$ can be expressed algebraically as functions of $y$ and a finite number of its derivatives:
\begin{equation}
    \begin{cases}
        x = x(y, \dot{y}, \ddot{y}, \ldots, y^{(r)}) \\
        u = u(y, \dot{y}, \ddot{y}, \ldots, y^{(r)})
    \end{cases}
\end{equation}}

\subsection{Application to Mobile Robots}
The Cartesian coordinates of unicycle and bicycle are flat outputs.

For unicycle geometric model:
\begin{equation}
    \begin{cases}
        x' = \tilde{v}\cos \theta \\
        y' = \tilde{v}\sin \theta \\
        \theta' = \tilde{\omega}
    \end{cases}
\end{equation}

Orientation from flat outputs:
\begin{equation}
    \theta = \theta(x', y') = \arctan(y'/x') + k\pi, \quad k = 0,1
\end{equation}

\note{The two possible choices for $\theta$ correspond to forward ($k=0$) or backward ($k=1$) motion. If initial orientation is assigned, then $k$ is determined.}

\subsection{Trajectory Generation}
From kinematic model:
\begin{equation}
    \begin{cases}
        \tilde{v}(s) = \pm\sqrt{x'(s)^2 + y'(s)^2} \\
        \tilde{\omega}(s) = \frac{y''(s)x'(s) - x''(s)y'(s)}{x'(s)^2 + y'(s)^2}
    \end{cases}
\end{equation}

Final control inputs:
\begin{equation}
    \begin{cases}
        v(t) = \tilde{v}(s)\dot{s}(t) \\
        \omega(t) = \tilde{\omega}(s)\dot{s}(t)
    \end{cases}
\end{equation}

\subsection{Path Planning Example}
For unicycle path from $q_i = [x_i \; y_i \; \theta_i]$ to $q_f = [x_f \; y_f \; \theta_f]$:

Use cubic polynomial:
\begin{equation}
    \begin{aligned}
        x(s) &= s^3x_f - (s-1)^3x_i + \alpha_x s^2(s-1) + \beta_x s(s-1)^2 \\
        y(s) &= s^3y_f - (s-1)^3y_i + \alpha_y s^2(s-1) + \beta_y s(s-1)^2
    \end{aligned}
\end{equation}

Boundary conditions:
\begin{equation}
    \begin{cases}
        x(0) = x_i & x(1) = x_f \\
        y(0) = y_i & y(1) = y_f \\
        x'(0) = k_i\cos\theta_i & x'(1) = k_f\cos\theta_f \\
        y'(0) = k_i\sin\theta_i & y'(1) = k_f\sin\theta_f
    \end{cases}
\end{equation}

where $k_i, k_f > 0$ are free parameters representing initial and final geometric speeds.

Parameters computed as:
\begin{equation}
    \begin{bmatrix}
        \alpha_x \\ \alpha_y
    \end{bmatrix} =
    \begin{bmatrix}
        k\cos\theta_f - 3x_f \\
        k\sin\theta_f - 3y_f
    \end{bmatrix}, \quad
    \begin{bmatrix}
        \beta_x \\ \beta_y
    \end{bmatrix} =
    \begin{bmatrix}
        k\cos\theta_i + 3x_i \\
        k\sin\theta_i + 3y_i
    \end{bmatrix}
\end{equation}

with $k_i = k_f = k$ chosen for simplicity.


\part{Mobile Robotics Navigation}

\chapter{Navigation Fundamentals}

\section{Introduction to Navigation}

\definitionbox{Navigation (IEEE Standard 172-1983): The process of directing a vehicle so as to reach the intended destination.}

This definition establishes the fundamental purpose of robot navigation - to enable autonomous movement from one point to another. The core challenge lies in developing reliable methods for a robot to:
\begin{itemize}
    \item Determine its current position
    \item Plan a path to the goal
    \item Execute the planned motion while avoiding obstacles
\end{itemize}

\section{Interaction with the Environment}

Robots frequently need to operate in unknown or partially known environments containing both static and dynamic obstacles. To navigate safely and effectively, robots must:

\begin{enumerate}
    \item Perceive and understand their environment through onboard sensors
    \item Recognize and locate obstacles in their path
    \item Plan and execute collision-free trajectories
\end{enumerate}

\subsection{Key Requirements}
For successful navigation in real-world environments, robots need:
\begin{itemize}
    \item Reliable sensing systems to detect obstacles
    \item Algorithms to process sensor data and identify potential hazards
    \item Motion planning capabilities to generate safe paths
    \item Control systems to execute planned movements accurately
\end{itemize}

\section{Navigation Approaches}

There are two fundamental approaches to robot navigation:

\subsection{Reactive Navigation}
\begin{itemize}
    \item Does not require a complete map of the environment
    \item Decisions are made based on current sensor readings
    \item Similar to biological systems like insects
    \item Can handle dynamic environments and unexpected obstacles
    \item Limited to simpler behaviors and local decision-making
\end{itemize}

\subsection{Map-Based Navigation}
\begin{itemize}
    \item Uses a representation of the environment (map)
    \item Enables global path planning
    \item Can find optimal routes
    \item Requires accurate localization
    \item More computationally intensive
    \item May struggle with dynamic environments
\end{itemize}

\note{The choice between reactive and map-based navigation often depends on the specific application requirements, environment characteristics, and available computational resources.}

\section{Navigation System Components}
A complete navigation system typically includes:
\begin{itemize}
    \item Perception: Sensors to gather information about the environment
    \item Localization: Methods to determine the robot's position
    \item Planning: Algorithms to generate paths to the goal
    \item Control: Systems to execute the planned motion
    \item Obstacle Avoidance: Strategies to prevent collisions
\end{itemize}

These components work together to enable the robot to navigate safely and efficiently from its current position to a desired destination, while avoiding obstacles and adapting to environmental changes.

\chapter{Reactive Navigation}

\section{Braitenberg Vehicles}

\subsection{Basic Concept}
Braitenberg vehicles, introduced by Valentino Braitenberg (Bolzano, 1924), represent a fundamental approach to reactive navigation. These vehicles demonstrate how simple sensor-motor connections can produce complex behaviors.

\definitionbox{A Braitenberg vehicle uses a simple neural network to process sensor signals on the left and right sides of the robot and applies the results directly to the motors.}

\subsection{Mathematical Model}
The vehicle's behavior is governed by two key equations:

\begin{enumerate}
    \item Vehicle speed:
    \begin{equation}
        v = 2 - s_R - s_L
    \end{equation}
    where $s_R$ and $s_L$ are the right and left sensor readings respectively.
    
    \item Steering angle:
    \begin{equation}
        \gamma = k(s_R - s_L)
    \end{equation}
\end{enumerate}

\note{At the goal position, where $s_R = s_L = 1$, the velocity becomes zero. When the sensor readings are equal, the robot moves straight ahead.}

\section{Bug Algorithms}

\subsection{Fundamental Principles}

Bug algorithms represent a class of reactive navigation methods based on the following principles:

\begin{itemize}
    \item Use of eteroceptive sensors (bumpers, range finders) to detect obstacles
    \item Simple behavior switching based on sensor inputs
    \item No requirement for global map knowledge
\end{itemize}

\subsection{Simplifying Assumptions}
The basic bug algorithms operate under the following assumptions:
\begin{itemize}
    \item Robot is modeled as a material point (no orientation control)
    \item Robot is equipped with a touch sensor
    \item Robot knows its position and the goal position at all times
\end{itemize}

\subsection{Bug Algorithm 1}

The algorithm alternates between two behaviors:

\subsubsection{Motion to Goal}
From a leave-point, the robot:
\begin{itemize}
    \item Moves along the m-line (line connecting leave-point to goal)
    \item Continues until either reaching goal or hitting an obstacle
    \item At obstacle contact, switches to boundary following
\end{itemize}

\subsubsection{Boundary Following}
When hitting an obstacle:
\begin{itemize}
    \item Circumnavigates the obstacle until returning to hit-point
    \item Determines closest point to goal along obstacle perimeter
    \item Moves to this point (new leave-point)
    \item Returns to motion to goal behavior
\end{itemize}

\begin{algorithmic}[1]
\State $i=1$; $q_L^0 = q_{start}$
\While{True}
    \Repeat
        \State from $q_L^{i-1}$, move toward $q_{goal}$
    \Until{$q_{goal}$ is reached or obstacle hit in $q_H^i$}
    \If{$q_{goal}$ is reached}
        \State Exit
    \EndIf
    \Repeat
        \State follow obstacle's border
    \Until{$q_{goal}$ is reached or $q_H^i$ is reached}
    \State determine $q_L^i$ on perimeter with minimal distance from $q_{goal}$
    \State go to $q_H^i$
    \If{m-line from $q_L^i$ crosses obstacle at $q_H^i$}
        \State report no solution
        \State Exit
    \EndIf
    \State $i = i + 1$
\EndWhile
\end{algorithmic}

\subsection{Bug Algorithm 2}

Key differences from Bug 1:
\begin{itemize}
    \item Uses fixed m-line (segment connecting start to goal)
    \item More opportunistic in leaving obstacles
    \item Generally more efficient for simple obstacles
\end{itemize}

\begin{algorithmic}[1]
\State $i=1$; $q_L^0 = q_{start}$
\While{True}
    \Repeat
        \State from $q_L^{i-1}$, move toward $q_{goal}$ on m-line
    \Until{$q_{goal}$ is reached or obstacle hit in $q_H^i$}
    \State turn left or right
    \Repeat
        \State follow obstacle's border
    \Until{$q_{goal}$ reached or $q_H^i$ reached or}
    \State new m-line point m found where:
    \State 1. $m \neq q_H^i$ 
    \State 2. $d(m,q_{goal}) < d(q_H^i,q_{goal})$
    \State 3. path to $q_{goal}$ is clear
    \State set $q_L^{i+1} = m$
    \State $i = i + 1$
\EndWhile
\end{algorithmic}

\section{Potential Fields}

\subsection{Basic Concept}
The potential field approach extends reactive navigation to systems with multiple degrees of freedom and enables real-time path modification.

\definitionbox{
Potential function: $U: \mathbb{R}^m \rightarrow \mathbb{R}$ with gradient
$\nabla U(q) = \left[\frac{\partial U(q)}{\partial q_1} \ldots \frac{\partial U(q)}{\partial q_n}\right]^T$
}

\subsection{Components}
The total potential field consists of:

\subsubsection{Attractive Potential}
\begin{itemize}
    \item $U_{att}(q)$ has minimum at $q_{goal}$
    \item Attracts robot to goal
    \item Possible choice: $U_{att} = \frac{1}{2}K_a\Delta(q,q_{goal})$
    \item Gradient: $\nabla U_{att} = K_a(q - q_{goal})$
\end{itemize}

\subsubsection{Repulsive Potential}
\begin{equation}
U_{rep} = \sum_{i=1}^{N_{obst}} U_{rep}^i(q)
\end{equation}

For each obstacle:
\begin{equation}
U_{rep}^i(q) = 
\begin{cases}
\frac{1}{2}K_r^i(\frac{1}{d_i(q)} - \frac{1}{q^*})^2 & d_i(q) \leq q^* \\
0 & d_i(q) > q^*
\end{cases}
\end{equation}

\subsection{Control Law}
The robot's motion is governed by:
\begin{equation}
\dot{q}(t) = -\nabla U(q)
\end{equation}
where $U(q) = U_{att}(q) + U_{rep}(q)$

\subsection{Limitations}
\begin{itemize}
    \item Local minima can trap the robot
    \item Not a complete planning method
    \item Solutions:
    \begin{itemize}
        \item Best first algorithm
        \item Randomized best first algorithm
        \item Noise addition
        \item Escape window algorithm
    \end{itemize}
\end{itemize}


\chapter{Map-Based Navigation}

\section{Distance Transform}

\definitionbox{The distance transform converts a binary matrix into another matrix where each element's value represents its distance from the nearest nonzero pixel in the original matrix.}

\subsection{Basic Concept}
The distance transform starts with:
\begin{itemize}
    \item An initial matrix of zeros
    \item A single nonzero element marking the goal
    \item Iterative computation of distances
\end{itemize}

\subsection{Distance Metrics}
Two common distance metrics are used:

\begin{enumerate}
    \item Euclidean distance:
    \begin{equation}
        d = \sqrt{\Delta_x^2 + \Delta_y^2}
    \end{equation}
    
    \item Manhattan (City Block) distance:
    \begin{equation}
        d = |\Delta_x| + |\Delta_y|
    \end{equation}
\end{enumerate}

\subsection{Computational Complexity}
The algorithm is computationally intensive:
\begin{itemize}
    \item Each iteration: $O(N^2)$ complexity
    \item Number of iterations: At least $O(N)$
    \item Total complexity: $O(N^3)$ where N is the map dimension
\end{itemize}

\section{Graph Search Algorithms}

\subsection{Dijkstra's Algorithm}

\subsubsection{Basic Characteristics}
\begin{itemize}
    \item Forward search from start to goal
    \item Objective function $f(n) = g(n)$
    \item $g(n)$ represents cost from start
\end{itemize}

\note{Dijkstra's algorithm always finds the optimal path but explores nodes in all directions.}

\subsection{A* Algorithm}

\subsubsection{Core Concepts}
\definitionbox{A* is an informed search algorithm that uses an evaluation function $f(n) = g(n) + h(n)$ where $g(n)$ is the cost from start and $h(n)$ is a heuristic estimate of cost to goal.}

Key components:
\begin{itemize}
    \item Operating cost function $g(n)$: Actual cost traversed
    \item Heuristic function $h(n)$: Estimated cost to goal
    \item Admissible heuristic: Never overestimates actual path cost
\end{itemize}

\subsubsection{Data Structures}
A* maintains two lists:
\begin{itemize}
    \item Open list (O): Stores nodes for expansion
    \item Closed list (C): Stores already explored nodes
\end{itemize}

\subsubsection{Algorithm Implementation}
\begin{algorithmic}[1]
\State Initialize open list with start node
\While{Open list not empty}
    \State Get node n with lowest f(n) from open list
    \If{n is goal}
        \State Return path
    \EndIf
    \State Move n to closed list
    \ForAll{neighbors m of n}
        \If{m not in closed list}
            \If{m not in open list}
                \State Add m to open list
            \Else
                \If{g(n) + c(n,m) < g(m)}
                    \State Update m's parent to n
                    \State Update g(m) and f(m)
                \EndIf
            \EndIf
        \EndIf
    \EndFor
\EndWhile
\State Return failure
\end{algorithmic}

\section{D* Algorithm}

\subsection{Introduction}
\definitionbox{D* (Dynamic A*) is a path planning algorithm that supports incremental replanning when arc costs change during execution.}

Key features:
\begin{itemize}
    \item Functionally equivalent to A* replanner
    \item Initially plans using Dijkstra's algorithm
    \item Caches intermediate data for efficient replanning
    \item More efficient than A* for complex environments
    \item Handles local changes without complete replanning
\end{itemize}

\subsection{State Representation}
Each cell in the map contains:
\begin{itemize}
    \item Cost (distance to goal)
    \item Backpointer to neighboring cell closest to goal
    \item State $t \in \{NEW, OPEN, CLOSED\}$
\end{itemize}

\subsection{Arc Costs}
\begin{itemize}
    \item Clear cells: Cost = 1 (horizontal/vertical), 1.4 (diagonal)
    \item Obstacle cells: Cost = 10000 (effectively infinite)
\end{itemize}

\subsection{Key Functions}
For a state X and neighbor Y:

\begin{equation}
c(X,Y) = \text{arc cost from Y to X}
\end{equation}

\begin{equation}
b(X) = Y \text{ indicates backpointer of X to Y}
\end{equation}

\begin{equation}
h(X) = \text{path cost estimate}
\end{equation}

\begin{equation}
k(X) = \text{smallest value of h(X) since X was placed on open list}
\end{equation}

\subsection{Algorithm States}
\subsubsection{Raise States}
A state X is called a raise state when:
\begin{equation}
h(X) > k(X)
\end{equation}

\subsubsection{Lower States}
A state X is called a lower state when:
\begin{equation}
h(X) = k(X)
\end{equation}

\subsection{Core Algorithm}
\begin{algorithmic}[1]
\State Initialize all states as NEW
\State Set goal state cost to zero and state to OPEN
\While{Open list not empty}
    \State Get state X with minimum k value
    \If{k(X) < h(X)}
        \ForAll{neighbors Y of X}
            \If{$h(Y) \leq k(X)$ and $h(X) > h(Y) + c(X,Y)$}
                \State $b(X) = Y$
                \State $h(X) = h(Y) + c(X,Y)$
            \EndIf
        \EndFor
    \EndIf
    \ForAll{neighbors $Y$ of $X$}
        \If{$Y$ is NEW or conditions for update met}
            \State Update $Y$'s backpointer and cost
            \State Add $Y$ to open list
        \EndIf
    \EndFor
\EndWhile
\end{algorithmic}

\subsection{Replanning}
When an obstacle is detected:
\begin{enumerate}
    \item Increase transition costs to obstacle cell
    \item Add affected cells to open list
    \item Process cells in order of increasing k values
    \item Update path costs and backpointers
    \item Continue until reaching current robot position
\end{enumerate}

\note{D* is particularly efficient because most path costs remain unchanged after encountering obstacles, allowing focused updates only where needed.}


\chapter{Roadmap Methods}

\section{Voronoi Roadmap}

\definitionbox{A Voronoi roadmap is a path planning approach based on thinning or skeletonization of free space, creating paths that maintain maximum clearance from obstacles.}

Key characteristics:
\begin{itemize}
   \item Computationally expensive iterative algorithm
   \item Illustrates principles of finding paths through free space
   \item Creates paths equidistant from nearby obstacles
   \item Ensures maximum clearance for robot navigation
\end{itemize}

\section{Probabilistic Roadmap Method (PRM)}

\subsection{Basic Concept}
PRM is a sampling-based planning method consisting of two phases:
\begin{enumerate}
   \item Learning (preprocessing) phase
   \item Query phase
\end{enumerate}

\subsection{Learning Phase}
During this phase, the algorithm:
\begin{itemize}
   \item Samples the configuration space sparsely
   \item Connects nearest neighbors with straight-line paths
   \item Verifies connections for collision-free movement
   \item Creates a network (graph) with:
   \begin{itemize}
       \item Minimal number of disjoint components
       \item No cycles (tree structure)
   \end{itemize}
\end{itemize}

\note{A key advantage of PRM is that relatively few points need to be tested to verify that points and paths between them are obstacle-free.}

\subsection{Connection Strategies}
For connecting nodes:
\begin{itemize}
   \item Connect to k-nearest neighbors
   \item Check path feasibility
   \item Maintain connection if collision-free
   \item Reject connection if path intersects obstacles
\end{itemize}

\subsection{Query Phase}
To find a path:
\begin{enumerate}
   \item Connect start point to closest roadmap node
   \item Find minimum cost route through roadmap
   \item Connect to node closest to goal
   \item Generate final path to goal point
\end{enumerate}

\section{Rapidly-Exploring Random Tree (RRT)}

\subsection{Introduction}
\definitionbox{RRT is a sampling-based algorithm that builds a space-filling tree by incrementally growing towards randomly selected points while considering the system's motion model.}

Key features:
\begin{itemize}
   \item Accounts for vehicle motion constraints
   \item Uses probabilistic methods like PRM
   \item Computes paths over fixed time intervals
   \item Considers discrete velocity values
   \item Handles both forward and backward motion
   \item Incorporates steering angle limits
\end{itemize}

\subsection{Configuration Space}
Each node represents a configuration:
\begin{equation}
q \in \mathbb{R}^2 \times S
\end{equation}

represented by a 3-dimensional vector:
\begin{equation}
q \sim (x, y, \theta)
\end{equation}

\subsection{Algorithm Implementation}
\begin{algorithmic}[1]
\State \textbf{Input:} Initial configuration $q_{init}$, number of vertices K, incremental distance $\Delta q$
\State \textbf{Output:} RRT graph G
\State G.init($q_{init}$)
\For{k = 1 to K}
   \State $q_{rand} \leftarrow$ RAND\_CONF(C)
   \State $q_{near} \leftarrow$ NEAREST\_VERTEX($q_{rand}$, G)
   \State $q_{new} \leftarrow$ NEW\_CONF($q_{near}$, $q_{rand}$, $\Delta q$)
   \State G.add\_vertex($q_{new}$)
   \State G.add\_edge($q_{near}$, $q_{new}$)
\EndFor
\State \Return G
\end{algorithmic}

\subsection{Obstacle Handling}
RRT handles obstacles through simple rules:
\begin{itemize}
   \item Discard $q_{rand}$ if it lies within an obstacle
   \item Reject $q_{near}$ if path to $q_{rand}$ intersects obstacle
   \item Result: collision-free, driveable roadmap
\end{itemize}

\subsection{Implementation Parameters}
For bicycle model implementation:
\begin{itemize}
   \item Velocity: $\pm 1$ m/s
   \item Steering angle limits: $\pm 0.5$ rad
   \item Integration period: 1 s
   \item Initial configuration: $(0,0,0)$
\end{itemize}

\subsection{Node Representation}
\begin{itemize}
   \item Each node indicated by marker in 3D configuration space
   \item Represents vehicle pose $(x,y,\theta)$
   \item Connected by feasible motion paths
   \item Forms tree structure expanding through free space
\end{itemize}

\subsection{Advantages}
\begin{itemize}
   \item Naturally respects motion constraints
   \item Efficient exploration of configuration space
   \item Simple obstacle avoidance implementation
   \item Handles complex vehicle dynamics
   \item Suitable for real-time planning
\end{itemize}

\note{RRT is particularly effective for systems with differential constraints and high-dimensional configuration spaces.}

\chapter{Robot Localization}

\section{Introduction}

\definitionbox{"In order to get somewhere we need to know where we are" - this fundamental principle underlies the process of localization, which is essential for robot navigation.}

Historical context:
\begin{itemize}
   \item Localization predates modern technology (GPS only since 1995)
   \item Traditional navigation methods rely on dead reckoning and landmarks
   \item Modern systems combine multiple approaches for robustness
\end{itemize}

\section{Dead Reckoning}

\definitionbox{Dead reckoning is the estimation of location based on estimated speed, direction, and time of travel with respect to a previous position estimate.}

\subsection{Basic Principles}
\begin{itemize}
   \item Integrates motion measurements over time
   \item Requires initial position knowledge
   \item Accumulates errors over distance
   \item Forms basis for basic odometry
\end{itemize}

\section{Odometry}

\definitionbox{Odometry is a technique to estimate the pose of a wheeled vehicle based on information from sensors which measure the space covered by the wheels and the angle of steering (if present).}

\subsection{System Requirements}
\begin{itemize}
   \item Knowledge of robot state (absolute position) for feedback control
   \item Incremental encoders on wheels for rotation measurement
   \item Runtime estimation procedure for actual position
\end{itemize}

\subsection{Unicycle Model Example}
Control inputs:
\begin{equation}
\begin{cases}
\dot{x} = v \cos \theta \\
\dot{y} = v \sin \theta \\
\dot{\theta} = \omega
\end{cases}
\end{equation}

Assumptions:
\begin{itemize}
   \item Constant inputs during each sampling interval
   \item Known configuration $q(t_k) = q_k$ at time instant $t_k$
   \item Inputs $v_k = v(t_k)$, $\omega_k = \omega(t_k)$ applied in $t \in [t_k, t_{k+1})$
   \item Sampling period $T_s = t_{k+1} - t_k$
\end{itemize}

\subsection{Integration Methods}

\subsubsection{Euler Method}
\begin{equation}
\begin{cases}
x_{k+1} = x_k + v_k T_s \cos \theta_k \\
y_{k+1} = y_k + v_k T_s \sin \theta_k \\
\theta_{k+1} = \theta_k + \omega_k T_s
\end{cases}
\end{equation}

Characteristics:
\begin{itemize}
   \item Error in $x_{k+1}, y_{k+1}$ computation due to constant $\theta_k$ assumption
   \item Correct for straight paths
   \item Error decreases with smaller $T_s$
   \item $\theta_{k+1}$ computation is exact
\end{itemize}

\subsubsection{Runge-Kutta Method (Second Order)}
\begin{equation}
\begin{cases}
x_{k+1} = x_k + v_k T_s \cos(\theta_k + \frac{\omega_k T_s}{2}) \\
y_{k+1} = y_k + v_k T_s \sin(\theta_k + \frac{\omega_k T_s}{2}) \\
\theta_{k+1} = \theta_k + \omega_k T_s
\end{cases}
\end{equation}

Improvements:
\begin{itemize}
   \item Uses mean value of $\theta_k$ for improved accuracy
   \item Reduced error in position computation
   \item Error still decreases with smaller $T_s$
   \item $\theta_{k+1}$ computation remains exact
\end{itemize}

\subsubsection{Precise Reconstruction}
\begin{equation}
\begin{cases}
x_{k+1} = x_k + \frac{v_k}{\omega_k}(\sin \theta_{k+1} - \sin \theta_k) \\
y_{k+1} = y_k - \frac{v_k}{\omega_k}(\cos \theta_{k+1} - \cos \theta_k) \\
\theta_{k+1} = \theta_k + \omega_k T_s
\end{cases}
\end{equation}

Where:
\begin{equation}
R = \frac{v_k}{\omega_k}
\end{equation}
represents the instantaneous radius of curvature at $t = t_k$

\note{For rectilinear case $\omega_k = 0 \rightarrow R = \infty$, equations degenerate to match Euler and Runge-Kutta results.}

\subsection{Practical Implementation}
For actual sensor readings:
\begin{equation}
\Delta s = \frac{r}{2}(\Delta \phi_r + \Delta \phi_l)
\end{equation}
\begin{equation}
\Delta \theta = \frac{r}{d}(\Delta \phi_r - \Delta \phi_l)
\end{equation}

Where:
\begin{itemize}
   \item $\Delta \phi_r, \Delta \phi_l$ are wheel rotation measurements
   \item $\Delta s$ is elementary path length
   \item $\Delta \theta$ is total orientation change
   \item $v_k T_s = \Delta s$ and $\omega_k T_s = \Delta \theta$
\end{itemize}

\subsection{Error Sources and Limitations}
Common problems:
\begin{itemize}
   \item Wheel slip
   \item Poor kinematic parameter calibration
   \item Numerical integration errors
   \item Accumulating drift regardless of method
   \item Limited reliability over long distances
\end{itemize}

\section{Pose Estimation}

\subsection{Probability Density Function (PDF)}
\begin{itemize}
   \item Describes robot's estimated position probabilistically
   \item PDF value not direct probability of position
   \item Probability is volume under PDF region
   \item Accounts for uncertainty in position estimate
\end{itemize}

\subsection{Next State Prediction}
Configuration update including odometry:
\begin{equation}
\hat{q}\langle k + 1\rangle = f(\hat{q}\langle k\rangle, \hat{v}\langle k\rangle) = 
\begin{bmatrix}
\hat{x}\langle k\rangle + \hat{v}_d \cos \hat{\theta}\langle k\rangle \\
\hat{y}\langle k\rangle + \hat{v}_d \sin \hat{\theta}\langle k\rangle \\
\hat{\theta}\langle k\rangle + \hat{v}_\theta
\end{bmatrix}
\end{equation}

\subsection{Noise Modeling}
Odometry noise model:
\begin{equation}
\hat{v}\langle k\rangle = v\langle k\rangle + \delta, \quad \delta = [\delta_d \; \delta_\theta]^T \sim N(0, V)
\end{equation}

Covariance matrix:
\begin{equation}
V = 
\begin{bmatrix}
\sigma_d^2 & 0 \\
0 & \sigma_\theta^2
\end{bmatrix}
\end{equation}

\note{The diagonal covariance matrix indicates independent errors in distance and heading measurements.}

\chapter{Mapping and SLAM}

\section{Map Building Fundamentals}

\subsection{Introduction}
Until now, we have assumed the existence of a map. However, map building is a crucial capability for autonomous robots. The process involves:
\begin{itemize}
   \item Robot equipped with range and bearing sensors
   \item Environment containing N landmarks
   \item Creating map of landmark locations
\end{itemize}

\subsection{Initial Assumptions}
For basic map building:
\begin{itemize}
   \item Robot knows its own location perfectly
   \item State vector comprises M observed landmarks
   \item Estimated coordinates form state vector:
   \begin{equation}
       \hat{q} = [x_1 \; y_1 \; x_2 \; y_2 \; \ldots \; x_M \; y_M]^T \in \mathbb{R}^{2M\times1}
   \end{equation}
\end{itemize}

\section{Map Building Process}

\subsection{Prediction Phase}
For stationary landmarks:
\begin{equation}
   \hat{q}^+\langle k + 1\rangle = \hat{q}\langle k\rangle
\end{equation}
\begin{equation}
   \hat{P}^+\langle k + 1\rangle = \hat{P}\langle k\rangle
\end{equation}

\subsection{Landmark Observation}
Function g(·) gives observed landmark coordinates:
\begin{equation}
   g(q_v, z) = \begin{bmatrix}
       x + r\cos(\theta + \beta) \\
       y + r\sin(\theta + \beta)
   \end{bmatrix}
\end{equation}

\subsection{State Vector Extension}
For new landmarks:
\begin{equation}
   \hat{q}' = y(\hat{q}, z, q_v) = \begin{bmatrix}
       \hat{q} \\
       g(q_v, z)
   \end{bmatrix}
\end{equation}

\subsection{Covariance Update}
Covariance matrix extension:
\begin{equation}
   \hat{P}'\langle k\rangle = Y_z \begin{bmatrix}
       \hat{P}\langle k\rangle & 0 \\
       0 & \hat{W}
   \end{bmatrix} Y_z^T
\end{equation}

Where insertion Jacobian:
\begin{equation}
   Y_z = \frac{\partial y}{\partial z} = \begin{bmatrix}
       I_{n\times n} & 0_{n\times 2} \\
       G_q & 0_{2\times n-3} & G_z
   \end{bmatrix}
\end{equation}

\section{SLAM Implementation}

\subsection{Problem Definition}
\definitionbox{Simultaneous Localization and Mapping (SLAM) or Concurrent Mapping and Localization (CML) involves determining robot position while simultaneously building a map of the environment.}

\subsection{State Vector}
Combined state vector including vehicle pose and landmarks:
\begin{equation}
   \hat{q} = [x \; y \; \theta \; x_1 \; y_1 \; x_2 \; y_2 \; \ldots \; x_M \; y_M]^T \in \mathbb{R}^{2M+3\times1}
\end{equation}

\subsection{Covariance Structure}
\begin{equation}
   \hat{P} = \begin{bmatrix}
       \hat{P}_{vv} & \hat{P}_{vm} \\
       \hat{P}_{vm}^T & \hat{P}_{mm}
   \end{bmatrix}
\end{equation}

Where:
\begin{itemize}
   \item $\hat{P}_{vv}$: Vehicle pose covariance
   \item $\hat{P}_{mm}$: Map landmark position covariance
   \item $\hat{P}_{vm}$: Vehicle-landmark correlation
\end{itemize}

\subsection{New Feature Updates}
When observing new features:
\begin{equation}
   G_q = \frac{\partial g}{\partial q} = \begin{bmatrix}
       1 & 0 & -r\sin(\hat{\theta} + \beta) \\
       0 & 1 & r\cos(\hat{\theta} - \beta)
   \end{bmatrix}
\end{equation}

\subsection{Observation Jacobian}
For SLAM:
\begin{equation}
   H_q = \frac{\partial h}{\partial p_i}\bigg|_{w=0} = [H_q^v \; \cdots \; 0 \; \cdots \; H_{p_i} \; \cdots \; 0] \in \mathbb{R}^{2\times(2M+3)}
\end{equation}

\note{The Kalman gain matrix distributes innovation from landmark observations to update both vehicle pose and landmark positions.}

\section{Laser-Based Mapping}

\subsection{Basic Concept}
\definitionbox{Laser-based mapping transforms laser scans into a global coordinate frame to build an occupancy grid map when robot pose is well-known through localization.}

\subsection{Occupancy Grid}
Map representation:
\begin{itemize}
   \item White cells: Free space
   \item Black cells: Occupied space
   \item Grey cells: Unknown areas
   \item Typical cell size: 10 cm
\end{itemize}

\subsection{Implementation Process}
\begin{enumerate}
   \item Obtain laser scan data
   \item Transform to global coordinates using robot pose
   \item Update occupancy grid:
   \begin{itemize}
       \item Mark cells between robot and obstacle as free
       \item Mark cells at obstacle distance as occupied
       \item Leave unexplored cells as unknown
   \end{itemize}
   \item Integrate multiple scans over time
\end{enumerate}

\subsection{Key Requirements}
For successful laser-based mapping:
\begin{itemize}
   \item Accurate robot localization
   \item Precise laser sensor calibration
   \item Proper scan registration
   \item Efficient grid update algorithms
\end{itemize}

\subsection{Advantages and Limitations}
Advantages:
\begin{itemize}
   \item Direct representation of free/occupied space
   \item Simple integration of new measurements
   \item Useful for path planning
\end{itemize}

Limitations:
\begin{itemize}
   \item Memory intensive for large environments
   \item Resolution limited by cell size
   \item Requires accurate pose estimation
\end{itemize}

\chapter{Monte Carlo Localization}

\section{Introduction}

\subsection{Motivation}
Traditional estimation methods assume Gaussian error distributions for sensors. However:
\begin{itemize}
   \item Real sensors may have non-Gaussian distributions (e.g., Poisson)
   \item Multi-modal distributions are common
   \item Need for more flexible estimation approach
\end{itemize}

\definitionbox{Monte Carlo Localization (MCL) makes no assumptions about error distributions and maintains multiple hypotheses about the vehicle's state, weighted by their likelihood of matching sensor observations.}

\section{Algorithm Components}

\subsection{State Representation}
\begin{itemize}
   \item Maintains N particles $q_i, i \in [1,N]$
   \item Each particle represents possible robot configuration
   \item Weighted by likelihood $w_i$ of matching observations
\end{itemize}

\subsection{Core Phases}
\begin{enumerate}
   \item Initialization
   \item Prediction
   \item Innovation
   \item Likelihood Computation
   \item Normalization
   \item Resampling
\end{enumerate}

\section{Algorithm Implementation}

\subsection{Initialization}
\begin{itemize}
   \item Create N particles randomly distributed over configuration space
   \item Assign initial weights: $w_i = 1/N$ for all particles
\end{itemize}

\subsection{Prediction}
Update each particle state:
\begin{equation}
   \hat{q}_i^+\langle k+1 \rangle = f(\hat{q}_i\langle k \rangle, \hat{u}\langle k \rangle + \delta\langle k \rangle)
\end{equation}
where $\delta\langle k \rangle$ is random noise with unknown distribution.

\subsection{Innovation}
For observation $z^\#$ of landmark j with map coordinate $p_j$:
\begin{equation}
   v_i = z^\#\langle k+1 \rangle - h(\hat{q}_i^+\langle k+1 \rangle, p_j)
\end{equation}

\subsection{Likelihood Computation}
Compute particle weights:
\begin{equation}
   w_i = e^{-v_i^T L^{-1}v_i} + w_0
\end{equation}
where:
\begin{itemize}
   \item $L$ is covariance-like matrix
   \item $w_0 > 0$ ensures finite retention probability
\end{itemize}

\subsection{Normalization}
Normalize weights:
\begin{equation}
   w_i' = \frac{w_i}{\sum_{i=1}^N w_i}
\end{equation}

\subsection{Resampling}
Select particles based on normalized weights:
\begin{equation}
   \hat{q}\langle k+1 \rangle \leftarrow R(\hat{q}^+\langle k+1 \rangle, w)
\end{equation}

\section{Complete Algorithm}

\begin{algorithmic}[1]
\State \textbf{Input:} $\hat{Q}\langle k \rangle = \{\hat{q}_1\langle k \rangle, \cdots, \hat{q}_N\langle k \rangle\}$, $\hat{u}\langle k \rangle$, $z^\#\langle k+1 \rangle$
\State \textbf{Output:} $\hat{Q}\langle k+1 \rangle$
\State $\hat{Q}\langle k+1 \rangle = \bar{Q}\langle k+1 \rangle = \emptyset, W = 0$
\For{i = 1 to N}
   \State $\hat{q}_i^+\langle k+1 \rangle = f(\hat{q}_i\langle k \rangle, \hat{u}\langle k \rangle + \delta\langle k \rangle)$
   \State $v_i = z^\#\langle k+1 \rangle - h(\hat{q}_i^+\langle k+1 \rangle, p_j)$
   \State $w_i = e^{-v_i^T L^{-1}v_i} + w_0$
   \State $W = W + w_i$
\EndFor
\For{i = 1 to N}
   \State $w_i' = w_i/W$
   \State $\bar{Q}\langle k+1 \rangle = \{\bar{Q}\langle k+1 \rangle, [\hat{q}_i^+\langle k+1 \rangle, w_i']\}$
\EndFor
\For{i = 1 to N}
   \State draw $\hat{q}_i\langle k+1 \rangle$ from $\bar{Q}\langle k+1 \rangle$ with probability $\propto w_i'$
   \State $\hat{Q}\langle k+1 \rangle = \{\hat{Q}\langle k+1 \rangle, \hat{q}_i\langle k+1 \rangle\}$
\EndFor
\State \Return $\hat{Q}\langle k+1 \rangle$
\end{algorithmic}

\section{Resampling Implementation}

\subsection{Process}
\begin{enumerate}
   \item Normalize weights
   \item Construct cumulative histogram: $c_j = \sum_{i=1}^j w_i'$
   \item Draw uniform random number $r \in [0,1]$
   \item Select particle based on where r falls in histogram
   \item Repeat N times
\end{enumerate}

\note{Particles with larger weights occupy larger portions of the cumulative histogram, increasing their selection probability.}

\section{Experimental Results}

\subsection{Initialization Phase}
\begin{itemize}
   \item Uniform distribution of particles
   \item Robot position unknown
   \item All locations equally likely
\end{itemize}

\subsection{Motion Updates}
\begin{itemize}
   \item Particles move according to robot motion
   \item Random noise added to particle motion
   \item Distribution spreads due to uncertainty
\end{itemize}

\subsection{Sensor Updates}
\begin{itemize}
   \item Particles weighted by sensor measurement likelihood
   \item Higher weights for particles matching observations
   \item Distribution concentrates in likely regions
\end{itemize}

\subsection{Convergence}
Experimental results show:
\begin{itemize}
   \item Initial high deviation in estimated path
   \item Rapid convergence between timesteps 10-20
   \item Elimination of particles far from true solution
   \item Final accurate position estimation
\end{itemize}

\subsection{Performance Metrics}
\begin{itemize}
   \item True path (blue) vs. estimated path (red)
   \item Particle deviation over time
   \item Convergence rate
   \item Estimation accuracy
\end{itemize}

\note{MCL combines the flexibility of particle representation with the efficiency of importance sampling to achieve robust localization in real-world environments.}









\end{document}










% divide these slides into chapters, afterwards I will ask you to transform it into a latex file, you have to be complete and accurate

% In latex using the preamble attached, be complete and precise